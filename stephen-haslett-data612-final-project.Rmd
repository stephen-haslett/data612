---
title: "DATA 612 Final Project"
author: "Stephen Haslett"
date: "07/10/2020"
output:
  html_document:
    theme: cosmo

subtitle: 'Amazon Magazine Subscriptions Recommender System'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(sparklyr)
library(dplyr)
library(plyr)
library(RCurl)
library(jsonlite)
```


## Assignment Instructions
Build out the system that you described in your final project planning document.

## Data Manipulation

### Pull in the datasets from GitHub
```{r, message=FALSE, warning=FALSE}
# Import the Json data from GitHub.
amazon_meta_source <- url('https://raw.githubusercontent.com/stephen-haslett/data612/612-final-project/amazon_magazine_meta.json')
amazon_ratings_source <- url('https://raw.githubusercontent.com/stephen-haslett/data612/612-final-project/amazon_magazine_ratings.json')

amazon_magazine_metadata <- do.call(rbind, lapply(paste(readLines(amazon_meta_source, warn = FALSE), collapse = ''), jsonlite::fromJSON))
amazon_magazine_ratings <- do.call(rbind, lapply(paste(readLines(amazon_ratings_source, warn = FALSE), collapse = ''), jsonlite::fromJSON))

head(amazon_magazine_metadata, 100)
head(amazon_magazine_ratings, 100)
```

### Remove the columns that we don't need.
```{r, message=FALSE, warning=FALSE}

metadata_refined <- select(amazon_magazine_metadata, asin, title)
# We only want items that have titles.
metadata_refined <- metadata_refined[!is.na(metadata_refined$title),]

ratings_refined <- select(amazon_magazine_ratings, asin, reviewerID, reviewerName, overall)
```


### Join the 2 tables together.
```{r, message=FALSE, warning=FALSE}
magazine_ratings <- join(ratings_refined, metadata_refined, by = 'asin', type = 'right')

# Remove rows that are missing reviewerID values.
magazine_ratings <- magazine_ratings[!is.na(magazine_ratings$reviewerID),]

# Rename column names to make them more descriptive.
names(magazine_ratings)[1] <- 'item_id'
names(magazine_ratings)[2] <- 'user_id'
names(magazine_ratings)[3] <- 'user_name'
names(magazine_ratings)[4] <- 'rating'
names(magazine_ratings)[5] <- 'item_name'

# item_ids and user_ids are alphanumeric. When we create the model, we use sparklyr's "ml_als()" function. The
# function's 'user_col' and 'item_col' parameter values must be integers, so we need to convert these to
# integer values.
item_factor <-as.factor(magazine_ratings$item_id)
item_id <- as.integer(item_factor)
magazine_ratings$item_id <- item_id

user_factor <- as.factor(magazine_ratings$user_id)
user_id <- as.integer(user_factor)
magazine_ratings$user_id <- user_id

head(magazine_ratings, 100)

```


## Copy the data over to Spark.
The dataset is too large for my local machine to handle, so I had to reduce the number of records to send over to Spark.
```{r, message=FALSE, warning=FALSE}
# Select the first 2000 records from the dataset to accommodate for limited resources on my local machine.
magazine_ratings <- head(magazine_ratings, 2000)

# Connect to Spark and copy over the dataset.
sc <- spark_connect(master = 'local', version = '3.0.0')
ratings <- sdf_copy_to(sc, magazine_ratings, overwrite = TRUE)

# Split the data into test and training sets.
partition <- ratings %>%  sdf_partition(training = 0.75, test = 0.25, seed = 1099)
training <- partition$training
test <- partition$test
```


## Create the Alternating Least Squares (ALS) model.
```{r, message=FALSE, warning=FALSE}
als_model <- ml_als(training, rating_col = 'rating', user_col = 'user_id', item_col = 'item_id')

summary(als_model)
```






