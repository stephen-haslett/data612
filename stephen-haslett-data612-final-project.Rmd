---
title: "DATA 612 Final Project"
author: "Stephen Haslett"
date: "07/10/2020"
output:
  html_document:
    theme: cosmo

subtitle: 'Amazon Magazine Subscriptions Recommender System'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(sparklyr)
library(dplyr)
library(plyr)
library(RCurl)
library(jsonlite)
```


## Assignment Instructions
Build out the system that you described in your final project planning document.

## Data Manipulation

### Pull in the datasets from GitHub
```{r, message=FALSE, warning=FALSE}
# Import the Json data from GitHub.
amazon_meta_source <- url('https://raw.githubusercontent.com/stephen-haslett/data612/612-final-project/amazon_magazine_meta.json')
amazon_ratings_source <- url('https://raw.githubusercontent.com/stephen-haslett/data612/612-final-project/amazon_magazine_ratings.json')

amazon_magazine_metadata <- do.call(rbind, lapply(paste(readLines(amazon_meta_source, warn = FALSE), collapse = ''), jsonlite::fromJSON))
amazon_magazine_ratings <- do.call(rbind, lapply(paste(readLines(amazon_ratings_source, warn = FALSE), collapse = ''), jsonlite::fromJSON))

head(amazon_magazine_metadata, 100)
head(amazon_magazine_ratings, 100)
```

### Remove the columns that we don't need.
```{r, message=FALSE, warning=FALSE}

metadata_refined <- select(amazon_magazine_metadata, asin, title)
# We only want items that have titles.
metadata_refined <- metadata_refined[!is.na(metadata_refined$title),]

ratings_refined <- select(amazon_magazine_ratings, asin, reviewerID, reviewerName, overall)
```


### Join the 2 tables together.
```{r, message=FALSE, warning=FALSE}
magazine_ratings <- join(ratings_refined, metadata_refined, by = 'asin', type = 'right')

# reviewerIDs are alphanumeric. When we create the model, we use sparklyr's "ml_als()" function. The
# 'user_col' parameter of this function must be an integer, so we need to strip out the alphabetic
# characters from the reviewerID, so that we are left with only numeric characters.
magazine_ratings$reviewerID <- as.numeric(gsub("[^0-9.-]", "", magazine_ratings$reviewerID))

# Remove rows that are missing reviewerID values.
magazine_ratings <- magazine_ratings[!is.na(magazine_ratings$reviewerID),]

# Rename table column names to be more descriptive.
names(magazine_ratings)[1] <- 'item'
names(magazine_ratings)[2] <- 'user_id'
names(magazine_ratings)[3] <- 'user_name'
names(magazine_ratings)[4] <- 'rating'
head(magazine_ratings, 2000)

```


## Copy the data over to Spark.
The dataset is too large for my local machine to handle, so I had to reduce the number of records to send over to Spark.
```{r, message=FALSE, warning=FALSE}
# Select the first 2000 records from the dataset to accommodate for limited resources on my local machine.
magazine_ratings <- head(magazine_ratings, 2000)

# Connect to Spark and copy over the dataset.
sc <- spark_connect(master = 'local', version = '3.0.0')
ratings <- sdf_copy_to(sc, magazine_ratings, overwrite = TRUE)

# Split the data into test and training sets.
partition <- ratings %>%  sdf_partition(training = 0.75, test = 0.25, seed = 1099)
training <- partition$training
test <- partition$test
```


## Create the Alternating Least Squares (ALS) model.
```{r, message=FALSE, warning=FALSE}
als_model <- ml_als(training, rating.column = 'rating', user.column = 'user_id', item.column = 'item', regularization.parameter = 0.01)

summary(als_model)
```






