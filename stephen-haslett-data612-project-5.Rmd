---
title: "Data 612 Project 5 | Implementing a Recommender System on Spark"
author: "Stephen Haslett"
date: "7/06/2020"
output:
  rmdformats::readthedown

subtitle: "Implementing a Recommender System on Spark"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(kableExtra)
library(recommenderlab)
library(sparklyr)
library(ggplot2)
library(rmdformats)
library(Metrics)
```

## Assignment Instructions
Adapt one of your recommendation systems to work with Apache Spark and compare the performance with your previous iteration.
Consider the efficiency of the system and the added complexity of using Spark.

Please include in your conclusion: For your given recommender systemâ€™s data, algorithm(s), and (envisioned) implementation, at
what point would you see moving to a distributed platform such as Spark becoming necessary?

## Introduction
For this assignment, I adapted the MovieLense recommender system I created for project 2 to work with Apache Spark. I then compared the performance
of the new distributed system with the previous interation from project 2.

## Data Manipulation

### Load the MovieLense Dataset
The MovieLense dataset contains 943 users, and 1664 movies.
```{r, warning=FALSE, message=FALSE}
set.seed(150)
data(MovieLense)
show(MovieLense)
```

### Select only users who have rated at least 50 movies, and movies that have been watched at least 100 times.
```{r, warning=FALSE, message=FALSE}
movie_ratings <- MovieLense[rowCounts(MovieLense) > 50, colCounts(MovieLense) > 100]
```


## Non Distributed Recommender System

#### Build the RecommenderLab ALS based model
```{r, warning=FALSE, message=FALSE}
e <- evaluationScheme(movie_ratings, method = 'split', train = 0.9, given = 15)
rec_als_model <- Recommender(getData(e, 'train'), method = 'ALS')
rec_als_model
```

### Perform predictions on the model and evaluate its accuracy.
```{r, warning=FALSE, message=FALSE}
start <- Sys.time()
predicted <- predict(rec_als_model, getData(e, 'known'), type = 'ratings')
stop <-Sys.time()
rec_als_model_accuracy <- calcPredictionAccuracy(predicted, getData(e, 'unknown'))
rec_als_model_accuracy

rec_time_taken <- stop - start
rec_time_taken
```

## Distributed Recommender System

#### Build the distributed ALS model and perform predictions
```{r, warning=FALSE, message=FALSE}
distributed_data <- movie_ratings %>% as(. , 'data.frame') %>% mutate(user = as.numeric(user), item = as.numeric(item)) 

# Open Spark connection.
sc <- spark_connect(master = "local", version = '3.0.0')

# Copy data to Spark.
spark_data <- sdf_copy_to(sc, distributed_data, 'sdf_rating_matrix', overwrite = TRUE)

# Split the Spark data into testing and training sets and build the model.
split_data <- spark_data %>% sdf_random_split(training = 0.9, testing = 0.2)
distributed_als_model <- ml_als(split_data$training, max_iter = 5)

# perform predictions.
start <- Sys.time()
predicted <- ml_transform(distributed_als_model, split_data$testing) %>% collect()
stop <-Sys.time()
dis_time_taken <- stop - start

# Close Spark connection.
spark_disconnect(sc)
```


## Side by Side Performance Evaluation
To evaluate the performance of the models, I will compare the time it took for each model to complete processing, and also compare their RMSE.

### Processing time comparision

```{r, warning=FALSE, message=FALSE}
processing_time <- rbind(rec_time_taken, dis_time_taken)

rownames(processing_time) <- c('RecommenderLab Model','Distributed Model')
colnames(processing_time) <- c('Processing Time')

knitr::kable(processing_time, format = 'html') %>%
  kableExtra::kable_styling(bootstrap_options = c('striped', 'hover')) %>% 
  add_header_above(c('Model Processing Time Comparision' = 2))
```

### RMSE comparision

```{r, warning=FALSE, message=FALSE}
# Get the RMSE from the RecommenderLab model. RecommenderLabs "calcPredictionAccuracy()" function takes
# care of calculating this for us, so we just need to fetch the value.
rec_rmse <- rec_als_model_accuracy[[1]]

# For the distributed model, we need to calcuate the RMSE ourselves. The Metrics package provides us
# with the rmse() function to take care of this task.
dis_rmse <- rmse(predicted$rating, predicted$prediction)


rmses <- rbind(rec_rmse, dis_rmse)

rownames(rmses) <- c('RecommenderLab Model','Distributed Model')
colnames(rmses) <- c('RMSE')

knitr::kable(rmses, format = 'html') %>%
  kableExtra::kable_styling(bootstrap_options = c('striped', 'hover')) %>% 
  add_header_above(c('Model RMSE Comparison' = 2))
```












