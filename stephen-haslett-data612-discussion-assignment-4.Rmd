---
title: "Data 612 Discussion Assignment 4"
author: "Stephen Haslett"
date: "07/03/2020"
output:
  rmdformats::readthedown

subtitle: 'Mitigating the Harm of Recommender Systems'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rmdformats)
```


## Assignment Instructions
Read one or more of the articles below and consider how to counter the radicalizing effects of recommender systems or ways to prevent algorithmic discrimination.

Renee Diresta, Wired.com (2018): [Up Next: A Better Recommendation System](https://www.wired.com/story/creating-ethical-recommendation-engines).

Zeynep Tufekci, The New York Times (2018): [YouTube, the Great Radicalizer](https://www.nytimes.com/2018/03/10/opinion/sunday/youtube-politics-radical.html).

Sanjay Krishnan, Jay Patel, Michael J. Franklin, Ken Goldberg (n/a): [Social Influence Bias in Recommender Systems: A Methodology for Learning, Analyzing, and Mitigating Bias in Ratings](https://goldberg.berkeley.edu/pubs/sanjay-recsys-v10.pdf).

## Discussion
In her New York Time's article - "YouTube, the Great Radicalizer", Zeynep Tufekci talks about how YouTube's recommendation algorithms seem to always up the stakes in terms of the extremity of the content they recommend to users based on their search history. During the 2016 presidential election campaign, she discovered that watching videos of Donald Trump would often result in YouTube recommending far right content. She experimented watching non political content, and found the same pattern emerged; watching content about vegetarianism led to videos about veganism, and videos about jogging led to videos about running ultramarathons being recommended.